{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/opt/conda/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Conv3D, Dense, Dropout, GlobalAveragePooling2D, MaxPooling2D, MaxPooling3D\n",
    "from keras.layers import Lambda, concatenate, Input, merge, Flatten, Reshape#, Concatenate\n",
    "# from keras.layers.core import Reshape\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from keras.utils import multi_gpu_model \n",
    "from keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from data_generator import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'keras.backend' from 'd:\\\\python\\\\python36\\\\lib\\\\site-packages\\\\keras\\\\backend\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(K)\n",
    "K.tf.__version__\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x2327bd9e470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def temporal_stream(input_shape=(224, 224, 20), verbose=1):\n",
    "        \n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    # conv1\n",
    "    opt_flow_conv = Conv2D(filters=96, \n",
    "                           kernel_size=(7, 7),\n",
    "                           strides=(2, 2), \n",
    "                           padding=\"same\",\n",
    "                           data_format=\"channels_last\",\n",
    "                           input_shape=input_shape,\n",
    "                           name=\"vggm_block1_conv1\")(input_tensor)\n",
    "\n",
    "    opt_flow_conv = BatchNormalization()(opt_flow_conv)\n",
    "    opt_flow_conv = Activation(\"relu\")(opt_flow_conv)\n",
    "    opt_flow_conv = MaxPooling2D(pool_size=(2, 2), name=\"vggm_block1_maxpool\")(opt_flow_conv)\n",
    "\n",
    "    # conv2\n",
    "    opt_flow_conv = Conv2D(filters=256, \n",
    "                           kernel_size=(5, 5), \n",
    "                           strides=(2, 2), \n",
    "                           padding=\"same\",\n",
    "                           name=\"vggm_block2_conv1\")(opt_flow_conv)\n",
    "\n",
    "    opt_flow_conv = Activation(\"relu\")(opt_flow_conv)\n",
    "    opt_flow_conv = MaxPooling2D(pool_size=(2, 2), name=\"vggm_block2_maxpool\")(opt_flow_conv)\n",
    "\n",
    "    # conv3\n",
    "    opt_flow_conv = Conv2D(filters=512, \n",
    "                           kernel_size=(3, 3), \n",
    "                           strides=1,\n",
    "                           activation=\"relu\", \n",
    "                           padding=\"same\",\n",
    "                           name=\"vggm_block3_conv1\")(opt_flow_conv)\n",
    "\n",
    "    # conv4\n",
    "    opt_flow_conv = Conv2D(filters=512,\n",
    "                           kernel_size=(3, 3), \n",
    "                           strides=(1, 1), \n",
    "                           activation=\"relu\", \n",
    "                           padding=\"same\",\n",
    "                           name=\"vggm_block4_conv1\")(opt_flow_conv)\n",
    "\n",
    "    # conv5\n",
    "    opt_flow_conv = Conv2D(filters=512,\n",
    "                           kernel_size=(3, 3), \n",
    "                           strides=(1, 1),\n",
    "                           activation=\"relu\", \n",
    "                           padding=\"same\",\n",
    "                           name=\"vggm_block5_conv1\")(opt_flow_conv)\n",
    "\n",
    "    opt_flow_conv = Conv2D(filters=512,\n",
    "                           kernel_size=(5, 5),\n",
    "                           strides=(1, 1), \n",
    "                           activation=\"relu\", \n",
    "                           padding=\"same\",\n",
    "                           name=\"vggm_block5_conv2\")(opt_flow_conv)\n",
    "\n",
    "#     opt_flow_conv = MaxPooling2D(pool_size=(2, 2))(opt_flow_conv)\n",
    "    \n",
    "    # create a shared model\n",
    "    tmp_stream = Model(input_tensor, opt_flow_conv, name=\"vggm\")\n",
    "\n",
    "    return tmp_stream\n",
    "\n",
    "temporal_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x2327cf935c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spatial_stream(input_shape=(224, 224, 3), verbose=1):\n",
    "            \n",
    "    input_tensor = Input(shape=input_shape)        \n",
    "            \n",
    "    # Block 1\n",
    "    x = Conv2D(filters=64, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block1_conv1\")(input_tensor)\n",
    "    \n",
    "    x = Conv2D(filters=64, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block1_conv2\")(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(filters=128, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block2_conv1\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=128, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block2_conv2\")(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(filters=256, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block3_conv1\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=256, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block3_conv2\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=256, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block3_conv3\")(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(filters=512, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block4_conv1\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=512, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block4_conv2\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=512, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block4_conv3\")(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(filters=512, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block5_conv1\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=512, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block5_conv2\")(x)\n",
    "    \n",
    "    x = Conv2D(filters=512, \n",
    "               kernel_size=(3, 3),\n",
    "               activation=\"relu\",\n",
    "               padding=\"same\",\n",
    "               name=\"block5_conv3\")(x)\n",
    "    \n",
    "#     x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    # Create model.\n",
    "    sp_stream = Model(input_tensor, x, name='vgg16')\n",
    "\n",
    "    return sp_stream\n",
    "\n",
    "spatial_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'rgb_img_0:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'rgb_img_1:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'rgb_img_2:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'rgb_img_3:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'rgb_img_4:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'opt_flow_0:0' shape=(?, 224, 224, 20) dtype=float32>, <tf.Tensor 'opt_flow_1:0' shape=(?, 224, 224, 20) dtype=float32>, <tf.Tensor 'opt_flow_2:0' shape=(?, 224, 224, 20) dtype=float32>, <tf.Tensor 'opt_flow_3:0' shape=(?, 224, 224, 20) dtype=float32>, <tf.Tensor 'opt_flow_4:0' shape=(?, 224, 224, 20) dtype=float32>]\n",
      "10\n",
      "[<tf.Tensor 'concatenate_1/concat:0' shape=(?, 14, 14, 1024) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, 14, 14, 1024) dtype=float32>, <tf.Tensor 'concatenate_3/concat:0' shape=(?, 14, 14, 1024) dtype=float32>, <tf.Tensor 'concatenate_4/concat:0' shape=(?, 14, 14, 1024) dtype=float32>, <tf.Tensor 'concatenate_5/concat:0' shape=(?, 14, 14, 1024) dtype=float32>]\n",
      "concatenate tensor =  (?, 5, 14, 14, 1024)\n",
      "<class 'int'>\n",
      "Tensor(\"spatiotemoral_dense4/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "rgb_img_0 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_0 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_img_1 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_1 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_img_2 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_2 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_img_3 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_3 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_img_4 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_4 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 14, 14, 512)  14714688    rgb_img_0[0][0]                  \n",
      "                                                                 rgb_img_1[0][0]                  \n",
      "                                                                 rgb_img_2[0][0]                  \n",
      "                                                                 rgb_img_3[0][0]                  \n",
      "                                                                 rgb_img_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "vggm (Model)                    (None, 14, 14, 512)  13163104    opt_flow_0[0][0]                 \n",
      "                                                                 opt_flow_1[0][0]                 \n",
      "                                                                 opt_flow_2[0][0]                 \n",
      "                                                                 opt_flow_3[0][0]                 \n",
      "                                                                 opt_flow_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           vgg16[1][0]                      \n",
      "                                                                 vggm[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1024) 0           vgg16[2][0]                      \n",
      "                                                                 vggm[2][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 14, 14, 1024) 0           vgg16[3][0]                      \n",
      "                                                                 vggm[3][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 14, 14, 1024) 0           vgg16[4][0]                      \n",
      "                                                                 vggm[4][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 14, 14, 1024) 0           vgg16[5][0]                      \n",
      "                                                                 vggm[5][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 5, 14, 14, 10 0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 5, 14, 14, 51 14156288    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 1, 7, 7, 512) 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 25088)        0           max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatiotemoral_dense1 (Dense)    (None, 2048)         51382272    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2048)         0           spatiotemoral_dense1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatiotemoral_dense2 (Dense)    (None, 1024)         2098176     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatiotemoral_dense3 (Dense)    (None, 512)          524800      spatiotemoral_dense2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "spatiotemoral_dense4 (Dense)    (None, 10)           5130        spatiotemoral_dense3[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 96,044,458\n",
      "Trainable params: 96,044,266\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x2327dba96d8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for lambda layer\n",
    "def antirectifier(list_of_tensors):\n",
    "    # [?, Time, Width, Height, Channel]\n",
    "    return K.stack(list_of_tensors, axis=1)\n",
    "\n",
    "def antirectifier_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 4  # only valid for 3D tensors\n",
    "    return shape\n",
    "\n",
    "# spatiotemporal model\n",
    "def spatiotemporal_cnn(img_shape=(224, 224), opt_flow_len=10, num_of_classes=10, num_of_snip=5):\n",
    "    \n",
    "    img_width = img_shape[0]\n",
    "    img_height = img_shape[1]\n",
    "    \n",
    "    sp_stream = spatial_stream(input_shape=(img_width, img_height, 3))  # spatiotemporal\n",
    "    tmp_stream = temporal_stream(input_shape=(img_width, img_height, opt_flow_len * 2))  # temporal\n",
    "\n",
    "    rgb_imgs = []\n",
    "    opt_flows = []\n",
    "    \n",
    "    input_tensors = []\n",
    "    for idx in range(num_of_snip):\n",
    "        rgb_input_name = \"rgb_img_{0}\".format(idx)\n",
    "        opt_flow_input_name = \"opt_flow_{0}\".format(idx)\n",
    "        rgb_imgs.append(Input(shape=(img_width, img_height, 3), name=rgb_input_name))\n",
    "        opt_flows.append(Input(shape=(img_width, img_height, opt_flow_len * 2), name=opt_flow_input_name))      \n",
    "#         input_tensors.append(rgb_imgs[-1])\n",
    "#         input_tensors.append(opt_flows[-1])\n",
    "        \n",
    "    input_tensors = rgb_imgs + opt_flows\n",
    "    \n",
    "    print(input_tensors)\n",
    "    print(len(input_tensors))\n",
    "        \n",
    "    output_tensors = []\n",
    "    for sp_tensor, tmp_tensor in zip(rgb_imgs, opt_flows):\n",
    "        concat_tensor = concatenate([sp_stream(sp_tensor), tmp_stream(tmp_tensor)])\n",
    "        output_tensors.append(concat_tensor)\n",
    "\n",
    "    print(output_tensors)\n",
    "    \n",
    "    concat_2_stream = Lambda(function=antirectifier, output_shape=None, mask=None, arguments=None)(output_tensors)\n",
    "    print(\"concatenate tensor = \", concat_2_stream.shape)\n",
    "\n",
    "    n_filters = int(concat_2_stream.shape[4] // 2)\n",
    "\n",
    "    print(type(n_filters))\n",
    "\n",
    "    Conv3D_2_stream = Conv3D(filters=n_filters, # 3d convolution over Time, Width, Height\n",
    "                             kernel_size=(3, 3, 3), # specifying the depth (<< notice this), height and width of the 3D convolution window. \n",
    "                             strides=(1, 1, 1), \n",
    "    #                          padding='valid', \n",
    "                             padding='same', \n",
    "                             data_format=\"channels_last\", \n",
    "    #                          dilation_rate=(1, 1, 1), \n",
    "                             activation=\"relu\", \n",
    "                             use_bias=True)(concat_2_stream)\n",
    "\n",
    "    MaxPool3D_2_stream = MaxPooling3D(pool_size=(num_of_snip, 2, 2), strides=(2, 2, 2), padding=\"valid\")(Conv3D_2_stream)\n",
    "    \n",
    "    x = Flatten()(MaxPool3D_2_stream)\n",
    "\n",
    "\n",
    "    x = Dense(2048, name=\"spatiotemoral_dense1\")(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Activation(\"elu\")(x)\n",
    "    x = Dropout(0.3)(x)    \n",
    "    x = Dense(1024, activation=\"relu\", name=\"spatiotemoral_dense2\")(x)\n",
    "    x = Dense(512, activation=\"relu\", name=\"spatiotemoral_dense3\")(x)\n",
    " \n",
    "    out = Dense(num_of_classes, activation='softmax', name=\"spatiotemoral_dense4\")(x)\n",
    "    print(out)\n",
    "\n",
    "    spatiotemporal_cnn = Model(inputs=input_tensors, outputs=out, name=\"spatiotemporal\")\n",
    "    print(spatiotemporal_cnn.summary())\n",
    "\n",
    "\n",
    "    return spatiotemporal_cnn\n",
    "\n",
    "spatiotemporal_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'rgb_img_0_1:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'rgb_img_1_1:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'rgb_img_2_1:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'rgb_img_3_1:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'rgb_img_4_1:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'opt_flow_0_1:0' shape=(?, 224, 224, 20) dtype=float32>, <tf.Tensor 'opt_flow_1_1:0' shape=(?, 224, 224, 20) dtype=float32>, <tf.Tensor 'opt_flow_2_1:0' shape=(?, 224, 224, 20) dtype=float32>, <tf.Tensor 'opt_flow_3_1:0' shape=(?, 224, 224, 20) dtype=float32>, <tf.Tensor 'opt_flow_4_1:0' shape=(?, 224, 224, 20) dtype=float32>]\n",
      "10\n",
      "[<tf.Tensor 'concatenate_6/concat:0' shape=(?, 14, 14, 1024) dtype=float32>, <tf.Tensor 'concatenate_7/concat:0' shape=(?, 14, 14, 1024) dtype=float32>, <tf.Tensor 'concatenate_8/concat:0' shape=(?, 14, 14, 1024) dtype=float32>, <tf.Tensor 'concatenate_9/concat:0' shape=(?, 14, 14, 1024) dtype=float32>, <tf.Tensor 'concatenate_10/concat:0' shape=(?, 14, 14, 1024) dtype=float32>]\n",
      "concatenate tensor =  (?, 5, 14, 14, 1024)\n",
      "<class 'int'>\n",
      "Tensor(\"spatiotemoral_dense4_1/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "rgb_img_0 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_0 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_img_1 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_1 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_img_2 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_2 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_img_3 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_3 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_img_4 (InputLayer)          (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_flow_4 (InputLayer)         (None, 224, 224, 20) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 14, 14, 512)  14714688    rgb_img_0[0][0]                  \n",
      "                                                                 rgb_img_1[0][0]                  \n",
      "                                                                 rgb_img_2[0][0]                  \n",
      "                                                                 rgb_img_3[0][0]                  \n",
      "                                                                 rgb_img_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "vggm (Model)                    (None, 14, 14, 512)  13163104    opt_flow_0[0][0]                 \n",
      "                                                                 opt_flow_1[0][0]                 \n",
      "                                                                 opt_flow_2[0][0]                 \n",
      "                                                                 opt_flow_3[0][0]                 \n",
      "                                                                 opt_flow_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 14, 14, 1024) 0           vgg16[1][0]                      \n",
      "                                                                 vggm[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 14, 14, 1024) 0           vgg16[2][0]                      \n",
      "                                                                 vggm[2][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 14, 14, 1024) 0           vgg16[3][0]                      \n",
      "                                                                 vggm[3][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 14, 14, 1024) 0           vgg16[4][0]                      \n",
      "                                                                 vggm[4][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 14, 14, 1024) 0           vgg16[5][0]                      \n",
      "                                                                 vggm[5][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 5, 14, 14, 10 0           concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 5, 14, 14, 51 14156288    lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 1, 7, 7, 512) 0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 25088)        0           max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatiotemoral_dense1 (Dense)    (None, 2048)         51382272    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 2048)         0           spatiotemoral_dense1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatiotemoral_dense2 (Dense)    (None, 1024)         2098176     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatiotemoral_dense3 (Dense)    (None, 512)          524800      spatiotemoral_dense2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "spatiotemoral_dense4 (Dense)    (None, 10)           5130        spatiotemoral_dense3[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 96,044,458\n",
      "Trainable params: 96,044,266\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape:0' shape=(1,) dtype=int32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape(spatiotemporal_cnn().output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatiotemporal_cnn_train(num_of_snip=5, \n",
    "                             opt_flow_len=10, \n",
    "                             image_shape=(224, 224),\n",
    "                             batch_size=32, \n",
    "                             nb_epoch=100, \n",
    "                             saved_model=None,\n",
    "                             class_limit=None, \n",
    "                             load_to_memory=False, \n",
    "                             name_str=None, \n",
    "                             gpus=1):\n",
    "    \n",
    "    \n",
    "    # Get local time.\n",
    "    time_str = time.strftime(\"%Y%m%d%H%M\", time.localtime())\n",
    "\n",
    "    if name_str == None:\n",
    "        name_str = \"spatiotemporal_cnn\"\n",
    "#         name_str = time_str\n",
    "\n",
    "    # Callbacks: Save the model.\n",
    "    saved_model_dir = os.path.join('out', 'checkpoints', name_str)\n",
    "    \n",
    "    if not os.path.exists(saved_model_dir):\n",
    "        os.makedirs(saved_model_dir)\n",
    "            \n",
    "#     checkpointer = ModelCheckpoint(filepath=os.path.join(saved_model_dir, '{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
    "    checkpointer = ModelCheckpoint(filepath=os.path.join(saved_model_dir, 'spatiotemproal_cnn_model.hdf5'),\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True, \n",
    "                                   save_weights_only=False, \n",
    "                                   monitor=\"loss\")\n",
    "\n",
    "    # Callbacks: TensorBoard\n",
    "    TensorBoard_dir = os.path.join('out', 'TB', name_str)\n",
    "    \n",
    "    if not os.path.exists(TensorBoard_dir):\n",
    "        os.makedirs(TensorBoard_dir)\n",
    "            \n",
    "    tb = TensorBoard(log_dir=os.path.join(TensorBoard_dir))\n",
    "\n",
    "    # Callbacks: Early stopper.\n",
    "    early_stopper = EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "    # Callbacks: Save results.\n",
    "    log_dir = os.path.join('out', 'logs', name_str)\n",
    "    \n",
    "    if not os.path.exists(log_dir):\n",
    "            os.makedirs(log_dir)\n",
    "            \n",
    "    timestamp = time.time()\n",
    "    csv_logger = CSVLogger(os.path.join(log_dir, 'spatiotemporal_cnn_training-' + str(timestamp) + '.log'))\n",
    "\n",
    "    # Callbacks: learning rate\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "    \n",
    "    # Learning rate schedule.\n",
    "#     lr_schedule = LearningRateScheduler(fixed_schedule, verbose=0)\n",
    "\n",
    "    # Get the data and process it.\n",
    "    if image_shape is None:\n",
    "        data = DataSet(num_of_snip=num_of_snip,\n",
    "                       opt_flow_len=opt_flow_len,\n",
    "                       class_limit=class_limit)\n",
    "    else:\n",
    "        data = DataSet(num_of_snip=num_of_snip,\n",
    "                       opt_flow_len=opt_flow_len,\n",
    "                       image_shape=image_shape,\n",
    "                       class_limit=class_limit)\n",
    "        \n",
    "#     print(\"temporal-train-, Show data list: {0}\".format(data.data_list))\n",
    "    \n",
    "    # Get samples per epoch.\n",
    "    # Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n",
    "#     steps_per_epoch = (len(data.data_list) * 0.7) // batch_size\n",
    "\n",
    "    steps_per_epoch = batch_size\n",
    "    \n",
    "    if load_to_memory:\n",
    "        # Get data.\n",
    "        X, y = data.get_all_stacks_in_memory('train')\n",
    "        X_test, y_test = data.get_all_stacks_in_memory('test')\n",
    "    else:\n",
    "        # Get generators.\n",
    "        generator = data.stack_generator(batch_size, 'train')\n",
    "        val_generator = data.stack_generator(batch_size, 'test', name_str=name_str)\n",
    "        \n",
    "    # Get the model.    \n",
    "    # Replicates `model` on 4 GPUs. \n",
    "    # This assumes that your machine has 4 available GPUs. \n",
    "    nb_classes = len(data.classes)\n",
    "\n",
    "    metrics = ['accuracy']\n",
    "    if nb_classes >= 10:\n",
    "            metrics.append('top_k_categorical_accuracy')\n",
    "\n",
    "    optimizer = SGD(lr=1e-2, momentum=0.9, nesterov=True)\n",
    "\n",
    "    \n",
    "    if saved_model is not None:\n",
    "        tmp_cnn = load_model(saved_model)\n",
    "    else:\n",
    "        \n",
    "        if gpus > 1:\n",
    "            print(\"# of GPUS:\", gpus)\n",
    "\n",
    "            tmp_model = spatiotemporal_cnn(img_shape=image_shape, opt_flow_len=opt_flow_len, num_of_classes=nb_classes)\n",
    "            tmp_cnn = multi_gpu_model(tmp_model, gpus=gpus)\n",
    "        else:\n",
    "            print(\"# of GPUS:\", gpus)\n",
    "\n",
    "            tmp_model = spatiotemporal_cnn(img_shape=image_shape, opt_flow_len=opt_flow_len, num_of_classes=nb_classes)\n",
    "            tmp_cnn = tmp_model\n",
    "\n",
    "        tmp_cnn.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "\n",
    "    \n",
    "    # Fit!\n",
    "    if load_to_memory:\n",
    "        # Use standard fit.\n",
    "#         temporal_cnn.model.fit(\n",
    "        tmp_cnn.fit(X,\n",
    "                    y,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[tb, early_stopper, csv_logger],\n",
    "                    epochs=nb_epoch)\n",
    "    else:\n",
    "        # Use fit generator.\n",
    "        print(\"temporal-train-, use fit generator\")\n",
    "#         temporal_cnn.model.fit_generator(\n",
    "        tmp_cnn.fit_generator(\n",
    "                generator=generator,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=nb_epoch,\n",
    "                verbose=1,\n",
    "                callbacks=[tb, early_stopper, csv_logger, checkpointer, reduce_lr],\n",
    "                validation_data=val_generator,\n",
    "                validation_steps=3,\n",
    "                max_queue_size=20,\n",
    "                workers=1,\n",
    "                use_multiprocessing=False)\n",
    "\n",
    "\n",
    "def main(gpus=1, load_saved_model=True):\n",
    "    \"\"\"\n",
    "    These are the main training settings. \n",
    "    Set each before running this file.\n",
    "    \"\"\"\n",
    "    config = {\"saved_model\": os.path.join('out', 'checkpoints', 'spatiotemporal_cnn', 'spatiotemproal_cnn_model.hdf5')}\n",
    "\n",
    "    saved_model = None\n",
    "    class_limit = None  # int, can be 1-101 or None\n",
    "    num_of_snip = 5 # number of chunks(snippets) used for each video\n",
    "    opt_flow_len = 10 # number of optical flow frames used\n",
    "#     image_shape=(224, 224)\n",
    "    image_shape=(64, 64)\n",
    "    load_to_memory = False  # pre-load the sequences into memory\n",
    "    batch_size = 128\n",
    "    nb_epoch = 2222\n",
    "    name_str = None\n",
    "\n",
    "    if os.path.exists(config[\"saved_model\"]) and load_saved_model:\n",
    "        saved_model = config[\"saved_model\"]\n",
    "        print(\"using saved model\")\n",
    "    \n",
    "    spatiotemporal_cnn_train(num_of_snip=num_of_snip, \n",
    "                             opt_flow_len=opt_flow_len, \n",
    "                             saved_model=saved_model,\n",
    "                             class_limit=class_limit, \n",
    "                             image_shape=image_shape,\n",
    "                             load_to_memory=load_to_memory, \n",
    "                             batch_size=batch_size,\n",
    "                             nb_epoch=nb_epoch, \n",
    "                             name_str=name_str,\n",
    "                             gpus=gpus)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './etc\\\\data_list.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-75291922301d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#main(gpus=2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-85926e88ec97>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(gpus, load_saved_model)\u001b[0m\n\u001b[0;32m    175\u001b[0m                              \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                              \u001b[0mname_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                              gpus=gpus)\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-85926e88ec97>\u001b[0m in \u001b[0;36mspatiotemporal_cnn_train\u001b[1;34m(num_of_snip, opt_flow_len, image_shape, batch_size, nb_epoch, saved_model, class_limit, load_to_memory, name_str, gpus)\u001b[0m\n\u001b[0;32m     66\u001b[0m                        \u001b[0mopt_flow_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt_flow_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                        \u001b[0mimage_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                        class_limit=class_limit)\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m#     print(\"temporal-train-, Show data list: {0}\".format(data.data_list))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\GoogleDrive\\ProgramDesign\\AIA\\AI\\FinalProject\\AI_final_project\\TwoStreamFusion\\data_generator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_of_snip, opt_flow_len, image_shape, original_image_shape, class_limit, config)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# Get the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# Get the classes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\GoogleDrive\\ProgramDesign\\AIA\\AI\\FinalProject\\AI_final_project\\TwoStreamFusion\\data_generator.py\u001b[0m in \u001b[0;36mget_data_list\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_data_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;34m\"\"\"Load our data list from file.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"etc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data_list\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './etc\\\\data_list.csv'"
     ]
    }
   ],
   "source": [
    "#main(gpus=2)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc and loss track\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "log_dir = os.path.join(os.getcwd(), 'out', 'logs', 'spatiotemporal_cnn')\n",
    "print(log_dir)\n",
    "for tmp in os.listdir(log_dir):\n",
    "    if tmp[0] != \".\":\n",
    "        \n",
    "        log_data = pd.read_csv(log_dir + \"/\" + tmp)\n",
    "        \n",
    "        print(log_data.columns)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        ax1 = plt.subplot2grid(shape=(2, 4), loc=(0, 0), rowspan=2, colspan=2)\n",
    "        ax1.set_xlabel(\"epoch\")\n",
    "        ax1.set_ylabel(\"loss\")\n",
    "        lg1 = ax1.plot(log_data[\"epoch\"], log_data[\"loss\"])\n",
    "        lg2 = ax1.plot(log_data[\"epoch\"], log_data[\"val_loss\"], color=\"blue\")\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2 = plt.subplot2grid(shape=(2, 4), loc=(0, 2), rowspan=2, colspan=2)\n",
    "        ax2.set_xlabel(\"epoch\")\n",
    "        ax2.set_ylabel(\"accuracy\")\n",
    "        lg2 = ax2.plot(log_data[\"epoch\"], log_data[\"acc\"])\n",
    "        lg2 = ax2.plot(log_data[\"epoch\"], log_data[\"val_acc\"], color=\"blue\")\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "# line, = ax.plot([1, 2, 3])\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yuzhe/Google 雲端硬碟/ProgramDesign/AIA/AI/FinalProject/AI_final_project/weight/spatiotemporal_cnn/spatiotemproal_cnn_model.hdf5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './etc/data_list.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7e89e6c674b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m gen_dataset = DataSet(num_of_snip=num_of_snip,\n\u001b[1;32m     28\u001b[0m                       \u001b[0mopt_flow_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_flow_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                       image_shape=image_shape, config=config)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mval_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 雲端硬碟/ProgramDesign/AIA/AI/FinalProject/AI_final_project/data_generator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_of_snip, opt_flow_len, image_shape, original_image_shape, class_limit, config)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Get the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Get the classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 雲端硬碟/ProgramDesign/AIA/AI/FinalProject/AI_final_project/data_generator.py\u001b[0m in \u001b[0;36mget_data_list\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;34m\"\"\"Load our data list from file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"etc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_list\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './etc/data_list.csv'"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "# saved_model = os.path.join(os.getcwd(), 'out', 'checkpoints', 'spatiotemporal_cnn', 'spatiotemproal_cnn_model.hdf5')\n",
    "# saved_model = os.path.join(os.getcwd(), 'weight', 'temporal_cnn', 'temproal_cnn_model.hdf5')\n",
    "saved_model = os.path.join(os.getcwd(), 'weight', 'spatiotemporal_cnn', 'spatiotemproal_cnn_model.hdf5')\n",
    "\n",
    "\n",
    "print(saved_model)\n",
    "model = load_model(saved_model)\n",
    "\n",
    "\n",
    "batch_size = 500\n",
    "class_limit = None  # int, can be 1-101 or None\n",
    "num_of_snip = 5 # number of chunks(snippets) used for each video\n",
    "opt_flow_len = 10 # number of optical flow frames used\n",
    "#     image_shape=(224, 224)\n",
    "image_shape=(64, 64)\n",
    "\n",
    "# model = temporal_cnn(img_shape, opt_flow_len, n_classes=5)\n",
    "\n",
    "\n",
    "config={\"etc\": \"./etc\", \n",
    "        \"data_list\": \"data_list.csv\", \n",
    "        \"img_path\": \"/home/jovyan/at073-group20/20bn_jester_500/train\",                          \n",
    "        \"opt_flow_path\": \"/home/jovyan/at073-group20/20bn_jester_500/optflow/train\"}\n",
    "\n",
    "gen_dataset = DataSet(num_of_snip=num_of_snip,\n",
    "                      opt_flow_len=opt_flow_len,\n",
    "                      image_shape=image_shape, config=config)\n",
    "\n",
    "val_generator = gen_dataset.stack_generator(batch_size, 'test')\n",
    "\n",
    "model = load_model(saved_model)\n",
    "print(model)\n",
    "\n",
    "val_classes = gen_dataset.classes\n",
    "print(val_classes)\n",
    "\n",
    "one_hot_idx = [gen_dataset.get_class_one_hot(tmp) for tmp in val_classes]\n",
    "print(one_hot_idx)\n",
    "\n",
    "\n",
    "\n",
    "# pd.replace\n",
    "\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "# for predict_idx in range(1):\n",
    "#     X, y = next(val_generator)\n",
    "#     print(len(X))\n",
    "    \n",
    "#     preds = model.predict(X)\n",
    "    \n",
    "#     for tmp_idx in range(batch_size):\n",
    "#         y_true.append(val_classes[np.argmax(y[tmp_idx])])\n",
    "#         y_pred.append(val_classes[np.argmax(preds[tmp_idx])])\n",
    "# #         print(val_classes[np.argmax(y[tmp_idx])], val_classes[np.argmax(preds[tmp_idx])])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "%matplotlib inline\n",
    "# Put the results in\n",
    "# y_true = \n",
    "# y_pred = \n",
    "\n",
    "\n",
    "labels = sorted(list(set(y_true)))\n",
    "cmx_d = confusion_matrix(y_pred, y_true, labels=labels)\n",
    "cmxn_d = cmx_d.astype('float') / cmx_d.sum(axis=0)[np.newaxis ,:]\n",
    "cmx_df = pd.DataFrame(cmx_d, index=labels, columns=labels)\n",
    "cmxn_df = pd.DataFrame(cmxn_d, index=labels, columns=labels)\n",
    "\n",
    "plt.figure(figsize = (14.5, 7))\n",
    "plt.subplot(121)\n",
    "sns.heatmap(cmxn_df, annot=True, cmap='YlGnBu', cbar=False)\n",
    "plt.title('Normalized confusion matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.tight_layout()\n",
    "plt.subplot(122)\n",
    "sns.heatmap(cmx_df, annot=True, cmap='YlGnBu', cbar=False)\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
